{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Models\n",
    "\n",
    "I believe Logistical regression will be the superior model based on initial research and the number of features being evaluated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler, RobustScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, AdaBoostRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up vairiables to be used in Fit Determination Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = []\n",
    "scores = {'Train Score': [], \"Test Score\": [], 'Test Train Difference': [], 'Scaler': []}\n",
    "scalers = [\"none\", StandardScaler(), MinMaxScaler(), MaxAbsScaler(), RobustScaler()]\n",
    "models = [LinearRegression(),\n",
    "          LogisticRegression(),\n",
    "          KNeighborsRegressor(),\n",
    "          RandomForestRegressor(),\n",
    "          RandomForestClassifier(),\n",
    "          ExtraTreesRegressor(),\n",
    "          ExtraTreesClassifier(),\n",
    "          AdaBoostRegressor(),\n",
    "          AdaBoostClassifier()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Function to Test Models and Scalers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(data):\n",
    "    for scaler in scalers:\n",
    "        global index\n",
    "        global scores\n",
    "        if scaler != \"none\":\n",
    "            scaler.fit(X_train)\n",
    "            X_train_scaled = scaler.transform(X_train)\n",
    "            X_test_scaled = scaler.transform(X_test)\n",
    "        else:\n",
    "            X_train_scaled = X_train\n",
    "            X_test_scaled = X_test\n",
    "        data = X_train_scaled, X_test_scaled, y_train, y_test\n",
    "        for model in models:\n",
    "            reg = model.fit(X_train_scaled, y_train)\n",
    "            y_pred = reg.predict(X_test_scaled)\n",
    "            scores[\"Train Score\"].append(reg.score(X_train_scaled, y_train))\n",
    "            scores[\"Test Score\"].append(reg.score(X_test_scaled, y_test))\n",
    "            scores[\"Test Train Difference\"].append((reg.score(X_train_scaled, y_train)-(reg.score(X_test_scaled, y_test))))\n",
    "            scores[\"Scaler\"].append(scaler)\n",
    "            index += [type(reg).__name__]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get data and evaluate readiness for model\n",
    "    * Find features and target \n",
    "    * Test for imbalance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_size</th>\n",
       "      <th>interest_rate</th>\n",
       "      <th>borrower_income</th>\n",
       "      <th>debt_to_income</th>\n",
       "      <th>num_of_accounts</th>\n",
       "      <th>derogatory_marks</th>\n",
       "      <th>total_debt</th>\n",
       "      <th>loan_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10700.0</td>\n",
       "      <td>7.672</td>\n",
       "      <td>52800</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>22800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8400.0</td>\n",
       "      <td>6.692</td>\n",
       "      <td>43600</td>\n",
       "      <td>0.311927</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>13600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9000.0</td>\n",
       "      <td>6.963</td>\n",
       "      <td>46100</td>\n",
       "      <td>0.349241</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>16100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10700.0</td>\n",
       "      <td>7.664</td>\n",
       "      <td>52700</td>\n",
       "      <td>0.430740</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>22700</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10800.0</td>\n",
       "      <td>7.698</td>\n",
       "      <td>53000</td>\n",
       "      <td>0.433962</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>23000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_size  interest_rate  borrower_income  debt_to_income  num_of_accounts  \\\n",
       "0    10700.0          7.672            52800        0.431818                5   \n",
       "1     8400.0          6.692            43600        0.311927                3   \n",
       "2     9000.0          6.963            46100        0.349241                3   \n",
       "3    10700.0          7.664            52700        0.430740                5   \n",
       "4    10800.0          7.698            53000        0.433962                5   \n",
       "\n",
       "   derogatory_marks  total_debt  loan_status  \n",
       "0                 1       22800            0  \n",
       "1                 0       13600            0  \n",
       "2                 0       16100            0  \n",
       "3                 1       22700            0  \n",
       "4                 1       23000            0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the data\n",
    "file_path = Path(\"Resources/lending_data.csv\")\n",
    "df = pd.read_csv(file_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    75036\n",
       "1     2500\n",
       "Name: loan_status, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of occurrences per target value. The classes are unbalanced.\n",
    "df[\"loan_status\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create X and Y | Reshape the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (77536, 7) (77536,)\n"
     ]
    }
   ],
   "source": [
    "# Create X (features) and y (target) sets\n",
    "X = df.drop(\"loan_status\", axis=1)\n",
    "y = df[\"loan_status\"].values\n",
    "print(\"Shape: \", X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizations used in testing \n",
    "# for col in X.columns:\n",
    "#     print(col)\n",
    "#     plt.scatter(X[col], y)\n",
    "#     plt.show()\n",
    "# reg = LinearRegression().fit(X_train, y_train)\n",
    "# print(reg.coef_)\n",
    "# plt.bar(X.columns, reg.coef_)\n",
    "# plt.show()\n",
    "# reg = Lasso(max_iter=10000).fit(X_train, y_train)\n",
    "# print(reg.coef_)\n",
    "# plt.bar(X.columns, reg.coef_)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data into Training and Testing sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "data = X_train, X_test, y_train, y_test = train_test_split(X, y, random_state= 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get to know our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.9331296646947465\n",
      "Testing Data Score: 0.7807456142682481\n",
      "[2.16103413e-02 7.79216318e-01 8.68852946e-02 3.38961395e-02\n",
      " 1.81182199e-02 2.38044201e-05 6.02498818e-02]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# setting Random forest as sample to view data \n",
    "classifier = RandomForestRegressor()\n",
    "clf = classifier.fit(X_train, y_train)\n",
    "print(f\"Training Data Score: {classifier.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {classifier.score(X_test, y_test)}\")\n",
    "\n",
    "features = clf.feature_importances_\n",
    "print(features)\n",
    "plt.bar(x = range(len(features)), height=features)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "features = sorted(zip(X.columns, clf.feature_importances_), key = lambda x: x[1])\n",
    "cols = [f[0] for f in features]\n",
    "width = [f[1] for f in features]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(10,5)\n",
    "plt.margins(y=0.001)\n",
    "\n",
    "ax.barh(y=cols, width=width)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of unique values in y_train:\n",
      "[[    0     1]\n",
      " [56244  1908]]\n"
     ]
    }
   ],
   "source": [
    "# Check the number of occurrences per target value in the training data\n",
    "unique_elements_train, counts_elements_train = np.unique(y_train, return_counts=True)\n",
    "print(\"Frequency of unique values in y_train:\")\n",
    "print(np.asarray((unique_elements_train, counts_elements_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check model/scaler combos for best fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call function test_model to test all models being considered\n",
    "test_model(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's look at our Scaler and Model Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Score</th>\n",
       "      <th>Test Score</th>\n",
       "      <th>Test Train Difference</th>\n",
       "      <th>Scaler</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.997197</td>\n",
       "      <td>0.992210</td>\n",
       "      <td>0.004987</td>\n",
       "      <td>MaxAbsScaler()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.997197</td>\n",
       "      <td>0.992158</td>\n",
       "      <td>0.005039</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.997197</td>\n",
       "      <td>0.991746</td>\n",
       "      <td>0.005451</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.997180</td>\n",
       "      <td>0.992004</td>\n",
       "      <td>0.005176</td>\n",
       "      <td>RobustScaler()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.997180</td>\n",
       "      <td>0.991797</td>\n",
       "      <td>0.005382</td>\n",
       "      <td>StandardScaler()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.994119</td>\n",
       "      <td>0.994170</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>RobustScaler()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.994119</td>\n",
       "      <td>0.994170</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>StandardScaler()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.992760</td>\n",
       "      <td>0.993087</td>\n",
       "      <td>-0.000327</td>\n",
       "      <td>MaxAbsScaler()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.992760</td>\n",
       "      <td>0.993087</td>\n",
       "      <td>-0.000327</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.991918</td>\n",
       "      <td>0.992468</td>\n",
       "      <td>-0.000550</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Train Score  Test Score  Test Train Difference  \\\n",
       "RandomForestClassifier     0.997197    0.992210               0.004987   \n",
       "RandomForestClassifier     0.997197    0.992158               0.005039   \n",
       "RandomForestClassifier     0.997197    0.991746               0.005451   \n",
       "RandomForestClassifier     0.997180    0.992004               0.005176   \n",
       "RandomForestClassifier     0.997180    0.991797               0.005382   \n",
       "LogisticRegression         0.994119    0.994170              -0.000052   \n",
       "LogisticRegression         0.994119    0.994170              -0.000052   \n",
       "LogisticRegression         0.992760    0.993087              -0.000327   \n",
       "LogisticRegression         0.992760    0.993087              -0.000327   \n",
       "LogisticRegression         0.991918    0.992468              -0.000550   \n",
       "\n",
       "                                  Scaler  \n",
       "RandomForestClassifier    MaxAbsScaler()  \n",
       "RandomForestClassifier              none  \n",
       "RandomForestClassifier    MinMaxScaler()  \n",
       "RandomForestClassifier    RobustScaler()  \n",
       "RandomForestClassifier  StandardScaler()  \n",
       "LogisticRegression        RobustScaler()  \n",
       "LogisticRegression      StandardScaler()  \n",
       "LogisticRegression        MaxAbsScaler()  \n",
       "LogisticRegression        MinMaxScaler()  \n",
       "LogisticRegression                  none  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print by Training Score\n",
    "df_scores = pd.DataFrame(scores, index=index)\n",
    "df_scores.sort_values('Train Score', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Score</th>\n",
       "      <th>Test Score</th>\n",
       "      <th>Test Train Difference</th>\n",
       "      <th>Scaler</th>\n",
       "      <th>Test Train Magnitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.994119</td>\n",
       "      <td>0.994170</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>0.000052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.994119</td>\n",
       "      <td>0.994170</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>RobustScaler()</td>\n",
       "      <td>0.000052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.992760</td>\n",
       "      <td>0.993087</td>\n",
       "      <td>-0.000327</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>0.000327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.992760</td>\n",
       "      <td>0.993087</td>\n",
       "      <td>-0.000327</td>\n",
       "      <td>MaxAbsScaler()</td>\n",
       "      <td>0.000327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.991918</td>\n",
       "      <td>0.992468</td>\n",
       "      <td>-0.000550</td>\n",
       "      <td>none</td>\n",
       "      <td>0.000550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.997197</td>\n",
       "      <td>0.992210</td>\n",
       "      <td>0.004987</td>\n",
       "      <td>MaxAbsScaler()</td>\n",
       "      <td>0.004987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.997197</td>\n",
       "      <td>0.992158</td>\n",
       "      <td>0.005039</td>\n",
       "      <td>none</td>\n",
       "      <td>0.005039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.997180</td>\n",
       "      <td>0.992004</td>\n",
       "      <td>0.005176</td>\n",
       "      <td>RobustScaler()</td>\n",
       "      <td>0.005176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.997180</td>\n",
       "      <td>0.991797</td>\n",
       "      <td>0.005382</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>0.005382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.997197</td>\n",
       "      <td>0.991746</td>\n",
       "      <td>0.005451</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>0.005451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Train Score  Test Score  Test Train Difference  \\\n",
       "LogisticRegression         0.994119    0.994170              -0.000052   \n",
       "LogisticRegression         0.994119    0.994170              -0.000052   \n",
       "LogisticRegression         0.992760    0.993087              -0.000327   \n",
       "LogisticRegression         0.992760    0.993087              -0.000327   \n",
       "LogisticRegression         0.991918    0.992468              -0.000550   \n",
       "RandomForestClassifier     0.997197    0.992210               0.004987   \n",
       "RandomForestClassifier     0.997197    0.992158               0.005039   \n",
       "RandomForestClassifier     0.997180    0.992004               0.005176   \n",
       "RandomForestClassifier     0.997180    0.991797               0.005382   \n",
       "RandomForestClassifier     0.997197    0.991746               0.005451   \n",
       "\n",
       "                                  Scaler  Test Train Magnitude  \n",
       "LogisticRegression      StandardScaler()              0.000052  \n",
       "LogisticRegression        RobustScaler()              0.000052  \n",
       "LogisticRegression        MinMaxScaler()              0.000327  \n",
       "LogisticRegression        MaxAbsScaler()              0.000327  \n",
       "LogisticRegression                  none              0.000550  \n",
       "RandomForestClassifier    MaxAbsScaler()              0.004987  \n",
       "RandomForestClassifier              none              0.005039  \n",
       "RandomForestClassifier    RobustScaler()              0.005176  \n",
       "RandomForestClassifier  StandardScaler()              0.005382  \n",
       "RandomForestClassifier    MinMaxScaler()              0.005451  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print by Testing Score\n",
    "df_scores.sort_values('Test Score', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Score</th>\n",
       "      <th>Test Score</th>\n",
       "      <th>Test Train Difference</th>\n",
       "      <th>Scaler</th>\n",
       "      <th>Test Train Magnitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.994119</td>\n",
       "      <td>0.994170</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>0.000052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.994119</td>\n",
       "      <td>0.994170</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>RobustScaler()</td>\n",
       "      <td>0.000052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.992760</td>\n",
       "      <td>0.993087</td>\n",
       "      <td>-0.000327</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>0.000327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.992760</td>\n",
       "      <td>0.993087</td>\n",
       "      <td>-0.000327</td>\n",
       "      <td>MaxAbsScaler()</td>\n",
       "      <td>0.000327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.991918</td>\n",
       "      <td>0.992468</td>\n",
       "      <td>-0.000550</td>\n",
       "      <td>none</td>\n",
       "      <td>0.000550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <td>0.708467</td>\n",
       "      <td>0.705684</td>\n",
       "      <td>0.002783</td>\n",
       "      <td>MaxAbsScaler()</td>\n",
       "      <td>0.002783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <td>0.677158</td>\n",
       "      <td>0.673339</td>\n",
       "      <td>0.003819</td>\n",
       "      <td>none</td>\n",
       "      <td>0.003819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.997197</td>\n",
       "      <td>0.992210</td>\n",
       "      <td>0.004987</td>\n",
       "      <td>MaxAbsScaler()</td>\n",
       "      <td>0.004987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.997197</td>\n",
       "      <td>0.992158</td>\n",
       "      <td>0.005039</td>\n",
       "      <td>none</td>\n",
       "      <td>0.005039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.997180</td>\n",
       "      <td>0.992004</td>\n",
       "      <td>0.005176</td>\n",
       "      <td>RobustScaler()</td>\n",
       "      <td>0.005176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Train Score  Test Score  Test Train Difference  \\\n",
       "LogisticRegression         0.994119    0.994170              -0.000052   \n",
       "LogisticRegression         0.994119    0.994170              -0.000052   \n",
       "LogisticRegression         0.992760    0.993087              -0.000327   \n",
       "LogisticRegression         0.992760    0.993087              -0.000327   \n",
       "LogisticRegression         0.991918    0.992468              -0.000550   \n",
       "AdaBoostRegressor          0.708467    0.705684               0.002783   \n",
       "AdaBoostRegressor          0.677158    0.673339               0.003819   \n",
       "RandomForestClassifier     0.997197    0.992210               0.004987   \n",
       "RandomForestClassifier     0.997197    0.992158               0.005039   \n",
       "RandomForestClassifier     0.997180    0.992004               0.005176   \n",
       "\n",
       "                                  Scaler  Test Train Magnitude  \n",
       "LogisticRegression      StandardScaler()              0.000052  \n",
       "LogisticRegression        RobustScaler()              0.000052  \n",
       "LogisticRegression        MinMaxScaler()              0.000327  \n",
       "LogisticRegression        MaxAbsScaler()              0.000327  \n",
       "LogisticRegression                  none              0.000550  \n",
       "AdaBoostRegressor         MaxAbsScaler()              0.002783  \n",
       "AdaBoostRegressor                   none              0.003819  \n",
       "RandomForestClassifier    MaxAbsScaler()              0.004987  \n",
       "RandomForestClassifier              none              0.005039  \n",
       "RandomForestClassifier    RobustScaler()              0.005176  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print by Testing Score\n",
    "df_scores['Test Train Magnitude'] = abs(df_scores['Test Train Difference'])\n",
    "df_scores.sort_values('Test Train Magnitude').head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit data to our model here we are fitting it using Logistic Regression\n",
    "    For Logistic Regression the model performed better when data is scaled \n",
    "    Both the standard scaler and the robust scaler performed identically\n",
    "    The Standard scaler is being used here. \n",
    "\n",
    "<span style='color:blue '> *Score provided = 0.9908171687990095* </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mLogistic Regression Results Tuned\u001b[0m \n",
      "\n",
      "\u001b[32mTraining Data Score: 0.9941188609162196\u001b[0m\n",
      "\u001b[32mTesting Data Score: 0.9941704498555509\u001b[0m\n",
      "\n",
      "\u001b[1mLogistic Regression Cross Validated Test Results Balanced\u001b[0m \n",
      "\n",
      "\u001b[32mTest Score Accuracy: 0.9939123267514247\u001b[0m\n",
      "\u001b[32mTest Score Accuracy Balanced: 0.9952328767780418\u001b[0m\n",
      "\n",
      "\u001b[1mLogistic Regression Classification Report\u001b[0m \n",
      "\n",
      "\u001b[32m              precision    recall  f1-score   support\n",
      "\n",
      "         Yes       1.00      0.99      1.00     18792\n",
      "          No       0.84      1.00      0.91       592\n",
      "\n",
      "    accuracy                           0.99     19384\n",
      "   macro avg       0.92      1.00      0.95     19384\n",
      "weighted avg       0.99      0.99      0.99     19384\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Scale using best scaler\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_s = scaler.transform(X_train)\n",
    "X_test_s = scaler.transform(X_test)\n",
    "\n",
    "# Train a Logistic Regression model print the model score\n",
    "classifier = LogisticRegression(random_state= 42)\n",
    "classifier.fit(X_train_s, y_train)\n",
    "print(f'\\033[1mLogistic Regression Results Tuned\\033[0m \\n')\n",
    "print(f'\\u001b[32mTraining Data Score: {classifier.score(X_train_s, y_train)}\\033[0m')\n",
    "print(f'\\u001b[32mTesting Data Score: {classifier.score(X_test_s, y_test)}\\033[0m\\n')\n",
    "\n",
    "# Cross validate to see if balancing will improve our model\n",
    "scoring = [\"accuracy\", \"balanced_accuracy\"]\n",
    "clf = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "cv_result = cross_validate(clf, X_test_s, y_test, scoring=scoring)\n",
    "print(f'\\033[1mLogistic Regression Cross Validated Test Results Balanced\\033[0m \\n')\n",
    "print(f'\\u001b[32mTest Score Accuracy: {cv_result[\"test_accuracy\"].mean()}\\033[0m')\n",
    "print(f'\\u001b[32mTest Score Accuracy Balanced: {cv_result[\"test_balanced_accuracy\"].mean()}\\033[0m\\n')\n",
    "\n",
    "# Review classification report to verify selections\n",
    "target_names = [\"Yes\", \"No\"]\n",
    "clf.fit(X_train_s, y_train)\n",
    "y_pred = clf.predict(X_test_s)\n",
    "print(f'\\033[1mLogistic Regression Classification Report\\033[0m \\n')\n",
    "print(f'\\u001b[32m{classification_report(y_test, y_pred, target_names=target_names)}\\033[0m')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit data to our model here we are fitting it using Random Forest Regression\n",
    "    Random Forest performed equally without regard for scaling \n",
    "    No scaling was performed on the data prior to fitting \n",
    "<span style='color:blue '> *Score provided = 0.9910751134956666* </span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mRandom Forest Classifier Results Tuned\u001b[0m \n",
      "\n",
      "\u001b[32mTraining Data Score: 0.9971970009629936\u001b[0m\n",
      "\u001b[32mTesting Data Score: 0.9921584812216261\u001b[0m\n",
      "\n",
      "\u001b[1mRandom Forest Classifier Results Balanced\u001b[0m \n",
      "\n",
      "\u001b[32mTest Score Accuracy: 0.9915393313428164\u001b[0m\n",
      "\u001b[32mTest Score Accuracy Balanced: 0.9391971682889423\u001b[0m\n",
      "\n",
      "\u001b[1mRandom Forest Classifier Classification Report\u001b[0m \n",
      "\n",
      "\u001b[32m              precision    recall  f1-score   support\n",
      "\n",
      "         Yes       1.00      0.99      1.00     18792\n",
      "          No       0.85      0.92      0.88       592\n",
      "\n",
      "    accuracy                           0.99     19384\n",
      "   macro avg       0.92      0.96      0.94     19384\n",
      "weighted avg       0.99      0.99      0.99     19384\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Train a Random Forest Classifier model and print the model score\n",
    "classifier = RandomForestClassifier(random_state=42, n_estimators= 500)\n",
    "classifier.fit(X_train, y_train)\n",
    "print(f'\\033[1mRandom Forest Classifier Results Tuned\\033[0m \\n')\n",
    "print(f'\\u001b[32mTraining Data Score: {classifier.score(X_train, y_train)}\\033[0m')\n",
    "print(f'\\u001b[32mTesting Data Score: {classifier.score(X_test, y_test)}\\033[0m\\n')\n",
    "\n",
    "# Cross validate to see if balancing will improve our model\n",
    "scoring = [\"accuracy\", \"balanced_accuracy\"]\n",
    "clf = RandomForestClassifier(class_weight='balanced')\n",
    "cv_result = cross_validate(clf, X_test, y_test, scoring=scoring)\n",
    "print(f'\\033[1mRandom Forest Classifier Results Balanced\\033[0m \\n')\n",
    "print(f'\\u001b[32mTest Score Accuracy: {cv_result[\"test_accuracy\"].mean()}\\033[0m')\n",
    "print(f'\\u001b[32mTest Score Accuracy Balanced: {cv_result[\"test_balanced_accuracy\"].mean()}\\033[0m\\n')\n",
    "\n",
    "# Review classification report to verify selections\n",
    "target_names = [\"Yes\", \"No\"]\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(f'\\033[1mRandom Forest Classifier Classification Report\\033[0m \\n')\n",
    "print(f'\\u001b[32m{classification_report(y_test, y_pred, target_names=target_names)}\\033[0m')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "The initial prediction may be incorrect as the Random Forest Classifier produced better training scores and only slightly lower testing scores.\n",
    "When we look at testing scores Logistic Regression performs better than Random Forest Classifier in all of its' variations. \n",
    "While Balancing improved the Logistic Regression model, predictably it did not improve the Random Forest Model. \n",
    "The Random Forest classifier produced identical results with and without scaling of any type. The Logistic regression model produced its best results when scaled by the standard scaler and the robust scaler, its results were improved again by balancing the data. \n",
    "None of the tested models appear to be experiencing overfitting, as a result no reduction in features were employed. \n",
    "The Random forest classifier model saw significant degredation when the data was balanced. \n",
    "When we look at the magnitude of the change between training and testing it appears that the initial prediction wins, Logistic regression experiences the lowest magnitude of change experienced between training and testing. \n",
    "The classification report(s) support these conclusions. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Notes for determiniation of n_estimators best value \n",
    "Three possible values are shown below\n",
    "values greater than 500 were tested but result in no\n",
    "change from the results of 500. \n",
    "n_estimators=500 was chosen. \n",
    "\n",
    "Random Forest Classifier Results Tuned (500) \n",
    "\n",
    "Training Data Score: 0.9971970009629936\n",
    "Testing Data Score: 0.9921584812216261\n",
    "\n",
    "Random Forest Classifier Results Balanced \n",
    "\n",
    "Training Score Balanced: 0.9921842696981313\n",
    "Test Score Balanced: 0.9536212376264211\n",
    "\n",
    "Random Forest Classifier Classification Report \n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         Yes       1.00      0.99      1.00     18792\n",
    "          No       0.85      0.92      0.89       592\n",
    "\n",
    "    accuracy                           0.99     19384\n",
    "   macro avg       0.92      0.96      0.94     19384\n",
    "weighted avg       0.99      0.99      0.99     19384\n",
    "\n",
    "Random Forest Classifier Results Tuned (250)\n",
    "\n",
    "Training Data Score: 0.9971970009629936\n",
    "Testing Data Score: 0.9921068922822947\n",
    "\n",
    "Random Forest Classifier Results Balanced \n",
    "\n",
    "Training Score Balanced: 0.9921971662676439\n",
    "Test Score Balanced: 0.9536279007394276\n",
    "\n",
    "Random Forest Classifier Classification Report \n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         Yes       1.00      0.99      1.00     18792\n",
    "          No       0.85      0.92      0.89       592\n",
    "\n",
    "    accuracy                           0.99     19384\n",
    "   macro avg       0.92      0.96      0.94     19384\n",
    "weighted avg       0.99      0.99      0.99     19384\n",
    "\n",
    "\n",
    "Random Forest Classifier Results Tuned (100)\n",
    "\n",
    "Training Data Score: 0.9971798046498831\n",
    "Testing Data Score: 0.9920037144036319\n",
    "\n",
    "Random Forest Classifier Results Balanced \n",
    "\n",
    "Training Score Balanced: 0.9922229619016523\n",
    "Test Score Balanced: 0.954027901183428\n",
    "\n",
    "Random Forest Classifier Classification Report \n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         Yes       1.00      0.99      1.00     18792\n",
    "          No       0.85      0.92      0.89       592\n",
    "\n",
    "    accuracy                           0.99     19384\n",
    "   macro avg       0.92      0.96      0.94     19384\n",
    "weighted avg       0.99      0.99      0.99     19384\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
